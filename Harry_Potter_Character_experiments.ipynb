{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Harry Potter Character experiments.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNczDdcGWh/N6531+ErX9pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shurm/Harry-Potter-Experiments/blob/master/Harry_Potter_Character_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3FA_evptBCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"drive/My Drive/\"\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es-CST68kVcu",
        "colab_type": "text"
      },
      "source": [
        "Stanford NER Tagger. Seems slightly more accurate then nltk pos_tag, but ITS REALLY SLOW."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BElRTrQgtGUN",
        "colab_type": "code",
        "outputId": "7043583d-9418-4916-8de3-0b57f8ea911c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "\"\"\"\n",
        "!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\n",
        "!unzip stanford-ner-2018-10-16.zip\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "\n",
        "\n",
        "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
        "                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n",
        "                       encoding='utf-8')\n",
        "text = None\n",
        "\n",
        "with open('harry_potter_fan_1.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "characters = set({})\n",
        "for sent in nltk.sent_tokenize(text):\n",
        "    tokens = nltk.tokenize.word_tokenize(sent)\n",
        "    tags = st.tag(tokens)\n",
        "    for tag in tags:\n",
        "        if tag[1]=='PERSON':\n",
        "            characters.add(tag)\n",
        "print(\"The following characters were found:\")\n",
        "print(characters)\n",
        "\n",
        "st = StanfordNERTagger('stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz', 'stanford-ner/stanford-ner.jar')\n",
        "tokenized_sents = [[word_tokenize(sent) for sent in sent_tokenize(text)] for filename in filelist]\n",
        "st.tag_sents(tokenized_sents)\n",
        "print(\"done\")\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-64638b5e02a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stanford-ner/stanford-ner.jar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtokenized_sents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilelist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0msearchpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stanford_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 verbose=verbose)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         self._stanford_model = find_file(model_filename,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_jar\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    719\u001b[0m         searchpath=(), url=None, verbose=False, is_regex=False):\n\u001b[1;32m    720\u001b[0m     return next(find_jar_iter(name_pattern, path_to_jar, env_vars,\n\u001b[0;32m--> 721\u001b[0;31m                          searchpath, url, verbose, is_regex))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             raise LookupError('Could not find %s jar file at %s' %\n\u001b[0;32m--> 637\u001b[0;31m                             (name_pattern, path_to_jar))\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;31m# Check environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: Could not find stanford-ner.jar jar file at stanford-ner/stanford-ner.jar"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmxRM6X6D2bU",
        "colab_type": "code",
        "outputId": "f6ceccfe-892c-409a-9b05-6788e7661e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Up here, we import additional functionality that we'll need to do this demo.\n",
        "\n",
        "# The Natural Language Processing Toolkit (NLTK) is a Python library with a lot\n",
        "# of really powerful tools for textual analysis.\n",
        "import nltk\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "# collections is a Python library with the super-awesome Counter, which takes a\n",
        "# list and returns a dictionary that tallies up how many times each value appears.\n",
        "# For example, ['red', 'red', 'rose'] would become [('red',  2), ('rose': 1)}.\n",
        "from collections import Counter\n",
        "# PrettyPrinter will make our final output easier to read in the console.\n",
        "import pprint\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) \n",
        "  \n",
        "story_delim = \"chapter 1\"\n",
        "harry_potter_file = open('harry_potter_fan_1.txt', 'r')\n",
        "#the first line is just \"chapter 1\"\n",
        "harry_potter_file.readline() \n",
        "\n",
        "#reads the large file one story at a time to prevent memory overflow\n",
        "def read_story():\n",
        "    '''\n",
        "    This function reads the text into python from a text file.\n",
        "    When you read in your own file, replace 'corpus/hp1.txt' with the path\n",
        "    to your file.\n",
        "    '''\n",
        "    story = []\n",
        "    while True: \n",
        "    \n",
        "      # Get next line from file \n",
        "      line = harry_potter_file.readline() \n",
        "      \n",
        "      # if line is empty \n",
        "      # end of file is reached \n",
        "      if not line: \n",
        "          break\n",
        "\n",
        "      if line.lower().strip() == story_delim:\n",
        "          break\n",
        "      \n",
        "      story.append(line)\n",
        "    \n",
        "    return \" \".join(story)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tagging(tokenize):\n",
        "    '''\n",
        "    This function takes the tokenized text created\n",
        "    by the text_tokenize function and tags each word with a code for the part of speech it represents\n",
        "    using NLTK's algorithm.  So, it changes the tokenized output:\n",
        "    ['Harry', 'hung', 'back', 'for', 'a', 'last', 'word',\n",
        "    'with', 'Ron', 'and', 'Hermione', '.']\n",
        "    - TO -\n",
        "    [('Harry', 'NNP'),\n",
        "    ('hung', 'VBD'), ('back', 'RP'), ('for', 'IN'), ('a', 'DT'), ('last', 'JJ'),\n",
        "    ('word', 'NN'), ('with', 'IN'), ('Ron', 'NNP'), ('and', 'CC'),\n",
        "    ('Hermione', 'NNP'), ('.', '.')]\n",
        "    '''\n",
        "    tagged_text = pos_tag(tokenize)\n",
        "    return tagged_text\n",
        "\n",
        "def find_proper_nouns(tagged_text):\n",
        "    '''\n",
        "    This function takes in the tagged text from the tagging function and Returns\n",
        "    a list of words that were tagged as proper nouns.  It does this by looking\n",
        "    at the second value in each word/tag pair - e.g. ('Harry', 'NNP') and determining\n",
        "    if is is equal to 'NNP'.\n",
        "\n",
        "    There are a lot of characters in these novels who are referred to with two\n",
        "    proper nouns, like 'Professor Quirell', 'Mrs. Weasley', or 'Uncle Vernon',\n",
        "    and any character can be called by their full name (e.g. 'Hermione Granger').\n",
        "\n",
        "    So, if the second value IS equal to 'NNP', we check the second value of the\n",
        "    next word - if it is also equal to 'NNP', we string the two words together\n",
        "    and add them to the proper_nouns list.\n",
        "\n",
        "    If the second value ISN'T equal to 'NNP', we append (add) only the first\n",
        "    word to the proper_nouns list.\n",
        "\n",
        "    As we add nouns to the list, we put them all in lower case - otherwise, our\n",
        "    program won't know that 'HARRY' is the same thing for our purposes as 'Harry'.\n",
        "    '''\n",
        "    proper_nouns = []\n",
        "    i = 0\n",
        "    while (i+1) < len(tagged_text):\n",
        "        if tagged_text[i][1] == 'NNP':\n",
        "            if tagged_text[i+1][1] == 'NNP':\n",
        "                proper_nouns.append(tagged_text[i][0] +\n",
        "                                    \" \" + tagged_text[i+1][0])\n",
        "                i+=1 # extra increment added to the i counter to skip the next word\n",
        "            #else:\n",
        "            #proper_nouns.append(tagged_text[i][0])\n",
        "        i+=1 # increment the i counter\n",
        "\n",
        "#    if (i+1)==len(tagged_text):\n",
        "#        if tagged_text[i][1] == 'NNP':\n",
        "#            proper_nouns.append(tagged_text[i][0])\n",
        "    return proper_nouns\n",
        "\n",
        "def summarize_text(proper_nouns, top_num):\n",
        "    '''\n",
        "    This function takes the proper_nouns from the list created by the\n",
        "    find_proper_nouns function and counts the instances of each.  For this demo,\n",
        "    we are using the most_common method that comes with the Counter.\n",
        "    '''\n",
        "    counts = dict(Counter(proper_nouns).most_common(top_num))\n",
        "    return counts\n",
        "\n",
        "# This is where we call all of our functions and pass what they return to the\n",
        "# next function\n",
        "\n",
        "num_characters = 100\n",
        "story_num = 1\n",
        "most_common_characters = Counter()\n",
        "while True:\n",
        "    story = read_story()\n",
        "    print(\"story\")\n",
        "    if len(story.strip())==0:\n",
        "        break\n",
        "    tokenized_text = word_tokenize(story)\n",
        "    print(\"word_tokenize\")\n",
        "    #fliter out\n",
        "    tokenized_text = [w for w in tokenized_text if w.lower() not in stop_words] \n",
        "    print(\"stop\")\n",
        "    tagged_text = pos_tag(tokenized_text)\n",
        "    print(\"pos_tag\")\n",
        "    proper_nouns_in_story = set(find_proper_nouns(tagged_text))\n",
        "    most_common_characters.update(proper_nouns_in_story)\n",
        "    print(story_num)\n",
        "    story_num+=1\n",
        "\n",
        "#close the file\n",
        "harry_potter_file.close()\n",
        "\n",
        "output = most_common_characters.most_common(num_characters)\n",
        "for o in output:\n",
        "    print(o)\n",
        "\n",
        "\"\"\"\n",
        "story_test = \"Harry needs to prepare the potions for tomorrow's class.\"\n",
        "tokenized_text = word_tokenize(story_test)\n",
        "tokenized_text = [w for w in tokenized_text if not w in stop_words] \n",
        "tagged_text = pos_tag(tokenized_text)\n",
        "print(tagged_text)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "1\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "2\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "3\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "4\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "5\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "6\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "7\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "8\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "9\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "10\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "11\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "12\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "13\n",
            "story\n",
            "word_tokenize\n",
            "stop\n",
            "pos_tag\n",
            "14\n",
            "story\n",
            "('Harry Potter', 13)\n",
            "('Great Hall', 12)\n",
            "('Diagon Alley', 11)\n",
            "('Ron Harry', 11)\n",
            "('Fred George', 11)\n",
            "('Ron Hermione', 10)\n",
            "('Hermione Granger', 9)\n",
            "('Harry Ginny', 9)\n",
            "('Mr. Weasley', 9)\n",
            "('Mrs. Weasley', 9)\n",
            "('Harry Ron', 9)\n",
            "('Professor McGonagall', 9)\n",
            "('Draco Malfoy', 8)\n",
            "('Death Eater', 8)\n",
            "('Hermione Ron', 8)\n",
            "('Dark Lord', 8)\n",
            "('Ministry Magic', 8)\n",
            "('Hermione Ginny', 8)\n",
            "('Head Boy', 8)\n",
            "('Minister Magic', 8)\n",
            "('Death Eaters', 8)\n",
            "('Hogwarts Express', 7)\n",
            "('Pansy Parkinson', 7)\n",
            "('James Potter', 7)\n",
            "('Harry Hermione', 7)\n",
            "('Remus Lupin', 7)\n",
            "('Leaky Cauldron', 7)\n",
            "('Lord Voldemort', 7)\n",
            "('Miss Granger', 7)\n",
            "('James Sirius', 7)\n",
            "('Professor Dumbledore', 7)\n",
            "('Sirius Black', 7)\n",
            "('Head Girl', 7)\n",
            "('Grimmauld Place', 7)\n",
            "('Daily Prophet', 7)\n",
            "('Uncle Vernon', 7)\n",
            "('Oh God', 6)\n",
            "('Malfoy Manor', 6)\n",
            "('Crabbe Goyle', 6)\n",
            "('Forbidden Forest', 6)\n",
            "('Professor Slughorn', 6)\n",
            "('Dark Arts', 6)\n",
            "('Remus Peter', 6)\n",
            "('Albus Dumbledore', 6)\n",
            "('Hogwarts School', 6)\n",
            "('Lucius Malfoy', 6)\n",
            "('Bill Charlie', 6)\n",
            "('History Magic', 6)\n",
            "('Mr. Malfoy', 6)\n",
            "('St. Mungo', 6)\n",
            "('Gryffindor Quidditch', 6)\n",
            "('Mr. Potter', 6)\n",
            "('Sirius James', 6)\n",
            "('Professor Flitwick', 6)\n",
            "('Defence Dark', 6)\n",
            "('Hermione Harry', 6)\n",
            "('Lily Evans', 6)\n",
            "('Madam Pomfrey', 6)\n",
            "('Privet Drive', 6)\n",
            "('Mr. Mrs.', 6)\n",
            "('Fred Weasley', 6)\n",
            "('George Weasley', 6)\n",
            "('Mum Dad', 6)\n",
            "('Defense Dark', 5)\n",
            "('Hermione Draco', 5)\n",
            "('Mrs. Granger', 5)\n",
            "('Ginny Weasley', 5)\n",
            "('Avada Kedavra', 5)\n",
            "('Care Magical', 5)\n",
            "('Draco Hermione', 5)\n",
            "('Thank Merlin', 5)\n",
            "('Order Phoenix', 5)\n",
            "('Tom Riddle', 5)\n",
            "('Godric Gryffindor', 5)\n",
            "('Arthur Weasley', 5)\n",
            "('Miss Evans', 5)\n",
            "('Witchcraft Wizardry', 5)\n",
            "('Harry Draco', 5)\n",
            "('JK Rowling', 5)\n",
            "('St. Mungos', 5)\n",
            "('James Lily', 5)\n",
            "('Yes Professor', 5)\n",
            "('Ronald Weasley', 5)\n",
            "('Room Requirement', 5)\n",
            "('Severus Snape', 5)\n",
            "('Wizard Wheezes', 5)\n",
            "('Sirius Remus', 5)\n",
            "('Aunt Petunia', 5)\n",
            "('Bellatrix Lestrange', 5)\n",
            "('Entrance Hall', 4)\n",
            "('Draco Harry', 4)\n",
            "('Mr. Granger', 4)\n",
            "('Mr. Ollivander', 4)\n",
            "('Hufflepuff Ravenclaw', 4)\n",
            "('Fat Lady', 4)\n",
            "('Lily Potter', 4)\n",
            "('Nearly Headless', 4)\n",
            "('J.K. Rowling', 4)\n",
            "('Professor Snape', 4)\n",
            "('Remus Sirius', 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nstory_test = \"Harry needs to prepare the potions for tomorrow\\'s class.\"\\ntokenized_text = word_tokenize(story_test)\\ntokenized_text = [w for w in tokenized_text if not w in stop_words] \\ntagged_text = pos_tag(tokenized_text)\\nprint(tagged_text)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhtrzyhrF4gR",
        "colab_type": "code",
        "outputId": "2acb766f-06ea-4766-e5d8-2cc89b0977fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\n",
        "#!unzip stanford-ner-2018-10-16.zip\n",
        "from nltk.tag.stanford import StanfordNERTagger\n",
        "\n",
        "\n",
        "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
        "                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n",
        "                       encoding='utf-8')\n",
        "\n",
        "#print(output)\n",
        "output2 = [w[0] for w in output] \n",
        "tags = st.tag(output2)\n",
        "for tag in tags:\n",
        "    print(tag)\n",
        "print(tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
            "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
            "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
            "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Harry', 'LOCATION')\n",
            "('Potter', 'LOCATION')\n",
            "('Great', 'LOCATION')\n",
            "('Hall', 'LOCATION')\n",
            "('Diagon', 'LOCATION')\n",
            "('Alley', 'LOCATION')\n",
            "('Ron', 'PERSON')\n",
            "('Harry', 'PERSON')\n",
            "('Fred', 'PERSON')\n",
            "('George', 'PERSON')\n",
            "('Ron', 'PERSON')\n",
            "('Hermione', 'PERSON')\n",
            "('Harry', 'PERSON')\n",
            "('Ginny', 'PERSON')\n",
            "('Mr.', 'O')\n",
            "('Weasley', 'PERSON')\n",
            "('Mrs.', 'O')\n",
            "('Weasley', 'PERSON')\n",
            "('Harry', 'PERSON')\n",
            "('Ron', 'PERSON')\n",
            "('Professor', 'PERSON')\n",
            "('McGonagall', 'PERSON')\n",
            "('Hermione', 'PERSON')\n",
            "('Granger', 'PERSON')\n",
            "('Draco', 'PERSON')\n",
            "('Malfoy', 'PERSON')\n",
            "('Death', 'O')\n",
            "('Eater', 'O')\n",
            "('Dark', 'O')\n",
            "('Lord', 'O')\n",
            "('Ministry', 'O')\n",
            "('Magic', 'O')\n",
            "('Head', 'O')\n",
            "('Boy', 'O')\n",
            "('Minister', 'O')\n",
            "('Magic', 'O')\n",
            "('Death', 'O')\n",
            "('Eaters', 'O')\n",
            "('Hogwarts', 'ORGANIZATION')\n",
            "('Express', 'ORGANIZATION')\n",
            "('Pansy', 'ORGANIZATION')\n",
            "('Parkinson', 'ORGANIZATION')\n",
            "('James', 'ORGANIZATION')\n",
            "('Potter', 'ORGANIZATION')\n",
            "('Hermione', 'ORGANIZATION')\n",
            "('Ron', 'ORGANIZATION')\n",
            "('Harry', 'ORGANIZATION')\n",
            "('Hermione', 'ORGANIZATION')\n",
            "('Remus', 'ORGANIZATION')\n",
            "('Lupin', 'ORGANIZATION')\n",
            "('Leaky', 'ORGANIZATION')\n",
            "('Cauldron', 'ORGANIZATION')\n",
            "('Lord', 'ORGANIZATION')\n",
            "('Voldemort', 'ORGANIZATION')\n",
            "('Miss', 'ORGANIZATION')\n",
            "('Granger', 'ORGANIZATION')\n",
            "('James', 'ORGANIZATION')\n",
            "('Sirius', 'ORGANIZATION')\n",
            "('Professor', 'O')\n",
            "('Dumbledore', 'PERSON')\n",
            "('Sirius', 'ORGANIZATION')\n",
            "('Black', 'ORGANIZATION')\n",
            "('Head', 'ORGANIZATION')\n",
            "('Girl', 'ORGANIZATION')\n",
            "('Grimmauld', 'ORGANIZATION')\n",
            "('Place', 'ORGANIZATION')\n",
            "('Dark', 'ORGANIZATION')\n",
            "('Arts', 'ORGANIZATION')\n",
            "('Uncle', 'ORGANIZATION')\n",
            "('Vernon', 'ORGANIZATION')\n",
            "('Malfoy', 'ORGANIZATION')\n",
            "('Manor', 'ORGANIZATION')\n",
            "('Crabbe', 'ORGANIZATION')\n",
            "('Goyle', 'ORGANIZATION')\n",
            "('Forbidden', 'ORGANIZATION')\n",
            "('Forest', 'ORGANIZATION')\n",
            "('Professor', 'O')\n",
            "('Slughorn', 'PERSON')\n",
            "('Remus', 'PERSON')\n",
            "('Peter', 'PERSON')\n",
            "('Albus', 'PERSON')\n",
            "('Dumbledore', 'PERSON')\n",
            "('Hogwarts', 'ORGANIZATION')\n",
            "('School', 'ORGANIZATION')\n",
            "('Lucius', 'PERSON')\n",
            "('Malfoy', 'PERSON')\n",
            "('Bill', 'PERSON')\n",
            "('Charlie', 'PERSON')\n",
            "('Mr.', 'O')\n",
            "('Malfoy', 'PERSON')\n",
            "('St.', 'O')\n",
            "('Mungo', 'O')\n",
            "('Gryffindor', 'O')\n",
            "('Quidditch', 'O')\n",
            "('Mr.', 'O')\n",
            "('Potter', 'PERSON')\n",
            "('Sirius', 'PERSON')\n",
            "('James', 'PERSON')\n",
            "('Professor', 'O')\n",
            "('Flitwick', 'ORGANIZATION')\n",
            "[('Harry', 'LOCATION'), ('Potter', 'LOCATION'), ('Great', 'LOCATION'), ('Hall', 'LOCATION'), ('Diagon', 'LOCATION'), ('Alley', 'LOCATION'), ('Ron', 'PERSON'), ('Harry', 'PERSON'), ('Fred', 'PERSON'), ('George', 'PERSON'), ('Ron', 'PERSON'), ('Hermione', 'PERSON'), ('Harry', 'PERSON'), ('Ginny', 'PERSON'), ('Mr.', 'O'), ('Weasley', 'PERSON'), ('Mrs.', 'O'), ('Weasley', 'PERSON'), ('Harry', 'PERSON'), ('Ron', 'PERSON'), ('Professor', 'PERSON'), ('McGonagall', 'PERSON'), ('Hermione', 'PERSON'), ('Granger', 'PERSON'), ('Draco', 'PERSON'), ('Malfoy', 'PERSON'), ('Death', 'O'), ('Eater', 'O'), ('Dark', 'O'), ('Lord', 'O'), ('Ministry', 'O'), ('Magic', 'O'), ('Head', 'O'), ('Boy', 'O'), ('Minister', 'O'), ('Magic', 'O'), ('Death', 'O'), ('Eaters', 'O'), ('Hogwarts', 'ORGANIZATION'), ('Express', 'ORGANIZATION'), ('Pansy', 'ORGANIZATION'), ('Parkinson', 'ORGANIZATION'), ('James', 'ORGANIZATION'), ('Potter', 'ORGANIZATION'), ('Hermione', 'ORGANIZATION'), ('Ron', 'ORGANIZATION'), ('Harry', 'ORGANIZATION'), ('Hermione', 'ORGANIZATION'), ('Remus', 'ORGANIZATION'), ('Lupin', 'ORGANIZATION'), ('Leaky', 'ORGANIZATION'), ('Cauldron', 'ORGANIZATION'), ('Lord', 'ORGANIZATION'), ('Voldemort', 'ORGANIZATION'), ('Miss', 'ORGANIZATION'), ('Granger', 'ORGANIZATION'), ('James', 'ORGANIZATION'), ('Sirius', 'ORGANIZATION'), ('Professor', 'O'), ('Dumbledore', 'PERSON'), ('Sirius', 'ORGANIZATION'), ('Black', 'ORGANIZATION'), ('Head', 'ORGANIZATION'), ('Girl', 'ORGANIZATION'), ('Grimmauld', 'ORGANIZATION'), ('Place', 'ORGANIZATION'), ('Dark', 'ORGANIZATION'), ('Arts', 'ORGANIZATION'), ('Uncle', 'ORGANIZATION'), ('Vernon', 'ORGANIZATION'), ('Malfoy', 'ORGANIZATION'), ('Manor', 'ORGANIZATION'), ('Crabbe', 'ORGANIZATION'), ('Goyle', 'ORGANIZATION'), ('Forbidden', 'ORGANIZATION'), ('Forest', 'ORGANIZATION'), ('Professor', 'O'), ('Slughorn', 'PERSON'), ('Remus', 'PERSON'), ('Peter', 'PERSON'), ('Albus', 'PERSON'), ('Dumbledore', 'PERSON'), ('Hogwarts', 'ORGANIZATION'), ('School', 'ORGANIZATION'), ('Lucius', 'PERSON'), ('Malfoy', 'PERSON'), ('Bill', 'PERSON'), ('Charlie', 'PERSON'), ('Mr.', 'O'), ('Malfoy', 'PERSON'), ('St.', 'O'), ('Mungo', 'O'), ('Gryffindor', 'O'), ('Quidditch', 'O'), ('Mr.', 'O'), ('Potter', 'PERSON'), ('Sirius', 'PERSON'), ('James', 'PERSON'), ('Professor', 'O'), ('Flitwick', 'ORGANIZATION')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}